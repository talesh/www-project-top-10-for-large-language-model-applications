% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}

\subsection{介绍}\label{ux4ecbux7ecd}

2022 年底，随着ChatGPT进入大众市场，人们对大型语言模型 (LLM)
的关注尤为浓厚。渴望利用大语言模型潜力的企业正在迅速将其整合到其运营和面向客户的产品中。然而，大语言模型的采用速度已经超过了全面安全协议的建立速度，导致许多应用程序容易受到高风险问题的影响。很明显，大语言模型还没有统一的资源来解决这些安全问题。很多开发者对于与LLM相关的安全风险不够了解，所以相关资源很分散。而OWASP正好能够协助推进这项技术的更安全应用。

\textbf{它是给谁用的？}
我们的主要受众是开发人员、数据科学家和安全专家，他们的任务是利用LLM技术设计和构建应用程序和插件。我们的目标是提供实用、可操作且简明的安全指南，帮助这些专业人士应对LLM申请安全复杂且不断变化的领域。

\textbf{清单的制定} 创建 OWASP LLM申请前 10
名列表是一项艰巨的任务，它建立在由近 500 名专家和超过 125
名积极贡献者组成的国际团队的集体专业知识的基础上。我们的贡献者来自不同的背景，包括人工智能公司、安全公司、ISV、云超大规模提供商、硬件提供商和学术界。

我们进行了一个月的集思广益，提出了潜在的漏洞，团队成员写下了 43
个不同的威胁。通过多轮投票，我们将这些提案细化为十大最关键漏洞的简明列表。专门的子团队仔细审查了每个漏洞并接受公众审查，以确保获得最全面且可操作的最终列表。

\textbf{与其他 OWASP 前 10 名列表相关} 虽然我们的列表与其他 OWASP Top 10
列表中发现的漏洞类型具有相同的
DNA，但我们并不是简单地重申这些漏洞。相反，我们深入研究这些漏洞在利用LLM的应用程序中遇到时的独特影响。

我们的目标是弥合一般应用程序安全原则和LLM提出的具体挑战之间的鸿沟。这包括探索传统漏洞如何可能带来不同的风险或如何在LLM内以新颖的方式被利用，以及传统的修复策略需要如何适应利用LLM的应用程序。

\textbf{关于1.1版本} 虽然我们的列表与其他 OWASP Top 10
列表中发现的漏洞类型具有相同的
DNA，但我们并不是简单地重申这些漏洞。相反，我们深入研究这些漏洞在利用
LLM
的应用程序中遇到时的独特影响。我们的目标是弥合一般应用程序安全原则和LLM提出的具体挑战之间的鸿沟。

该小组的目标包括探索传统漏洞如何在LLM内造成不同的风险或以新颖的方式被利用，以及开发人员如何必须针对利用LLM的应用程序调整传统的修复策略。

\textbf{未来} 列表中的 v1.1
不会是我们的最后一个。我们希望定期更新，以跟上行业状况。我们将与更广泛的社区合作，推动最先进的技术，并为各种用途创造更多的教育材料。我们还寻求与标准机构和政府就人工智能安全主题进行合作。我们欢迎您加入我们的团队并做出贡献。

\subsubsection{签名}\label{ux7b7eux540d}

\subsubsection{史蒂夫·威尔逊 (Steve
Wilson)}\label{ux53f2ux8482ux592bux5a01ux5c14ux900a-steve-wilson}

项目负责人，OWASP Top 10 for LLM Applications\\
\href{https://www.linkedin.com/in/wilsonsd/}{https://www.linkedin.com/in/wilsonsd}\\
Twitter/X：@virtualsteve

\subsubsection{Ads Dawson}\label{ads-dawson}

v1.1 版本负责人和漏洞条目负责人，OWASP Top 10 for LLM Applications\\
\href{https://www.linkedin.com/in/adamdawson0/}{https://www.linkedin.com/in/adamdawson0}\\
GitHub：@GangGreenTemperTatum

\subsection{关于本次翻译}\label{ux5173ux4e8eux672cux6b21ux7ffbux8bd1}

\subsubsection{翻译作者}\label{ux7ffbux8bd1ux4f5cux8005}

\begin{itemize}
\tightlist
\item
  \textbf{黄连金 (Ken Huang)}\\
  \href{https://www.linkedin.com/in/kenhuang8/}{https://www.linkedin.com/in/kenhuang8}
\end{itemize}

认识到 OWASP Top 10 for LLM Applications
的非凡技术性和关键性，我们有意识地选择在创作此翻译时仅雇用人工翻译。上述译者不仅对原文内容有深刻的理解，而且语言流畅，有信心使翻译取得成功

Talesh Seeparsan\\
翻译主任 OWASP Top 10 for LLM Applications
\href{https://www.linkedin.com/in/talesh/}{https://www.linkedin.com/in/talesh}

\subsection{OWASP 大语言模型人工智能应用Top 10
安全威胁}\label{owasp-ux5927ux8bedux8a00ux6a21ux578bux4ebaux5de5ux667aux80fdux5e94ux7528top-10-ux5b89ux5168ux5a01ux80c1}

\textbf{LLM01：提示词(Prompt) 注入(Injection)}
黑客通过设计过的输入（提示词）操纵大型语言模型 (LLM)，从而导致 LLM
执行意外操作。提示词注入会覆盖系统提示词，而间接注入操纵外部数据源进行注入攻击。

\textbf{LLM02 不安全的输出处理} 当 LLM
输出未经审查而被接受时，就会出现此漏洞，从而暴露后端系统。滥用可能会导致
XSS、CSRF、SSRF、权限升级或远程代码执行等严重后果。

\textbf{LLM03 训练数据中毒} 当 LLM
培训数据被篡改，引入损害安全性、有效性或道德行为的漏洞或偏见时，就会发生这种情况。来源包括
Common Crawl、 WebText 、 OpenWebText和书籍。

\textbf{LLM04 拒绝服务模型}
攻击者对大型语言模型进行资源密集型操作，导致服务降级或高成本。由于LLM的资源密集型性质和用户输入的不可预测性，该漏洞被放大。

\textbf{LLM05 供应链漏洞} LLM
应用程序生命周期可能会受到易受攻击的组件或服务的影响，从而导致安全攻击。使用第三方数据集、预先训练的模型和插件可能会增加漏洞。

\textbf{LLM06 敏感信息披露}
LLM可能会在其回复中泄露机密数据，从而导致未经授权的数据访问、隐私侵犯和安全漏洞。实施数据清理和严格的用户策略来缓解这种情况至关重要。

\textbf{LLM07 不安全的插件设计} LLM
插件可能具有不安全的输入和不足的访问控制。缺乏应用程序控制使它们更容易被利用，并可能导致远程代码执行等后果。

\textbf{LLM08 过度代理}
基于LLM的系统可能会采取导致意想不到的后果的行动。该问题源于授予基于 LLM
的系统过多的功能、权限或自主权。

\textbf{LLM09 过度依赖}
过度依赖LLM而不受监督的系统或人员可能会因LLM生成的不正确或不适当的内容而面临错误信息、沟通不畅、法律问题和安全漏洞。

\textbf{LLM10 模型盗窃}
这涉及对专有LLM模型的未经授权的访问、复制或泄露。影响包括经济损失、竞争优势受损以及敏感信息的潜在访问。

\end{document}
