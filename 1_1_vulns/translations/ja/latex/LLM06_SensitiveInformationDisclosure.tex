% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}

\subsection{LLM06:
機微情報の漏出}\label{llm06-ux6a5fux5faeux60c5ux5831ux306eux6f0fux51fa}

\subsubsection{Description}\label{description}

LLMアプリケーションは、その出力を通じて機微情報、独自のアルゴリズム、またはその他の機密情報を公開してしまう可能性があります。その結果、機密データへの不正アクセス、知的財産やプライバシー侵害、その他のセキュリティ侵害を引き起こす可能性があります。LLMアプリケーションの利用者は、LLMと安全にやりとりする方法を認識し、機密データを意図せずに入力すると、それが他のどこかで出力され得ることに関連するリスクを特定することが重要です。

このリスクを軽減するため、LLMアプリケーションは、ユーザーデータが訓練データに混入しないように、適切にデータのサニタイズを行う必要があります。また、LLMアプリケーションの所有者は、適切な利用規約を用意し、利用者のデータがどのように処理されるか、及び自分のデータがモデルの訓練に含まれることをオプトアウトできるかについて、利用者に対して認識させる必要があります。

LLMと利用者アプリケーションの相互インタラクションは、双方向の信頼境界を形成しますが、クライアントからLLMへの入力、およびLLMからクライアントへの出力のそれぞれは本質的に信頼できません。この脆弱性は、脅威モデリング演習、安全なインフラ、適切なサンドボックスなどの、特定の前提条件については範囲外であると想定していることに注意することが重要です。LLMが返すべきデータの種類に関する制限をシステム・プロンプト内に追加することで、機密情報の漏出を緩和できる可能性があります。しかし、LLMには予測不可能な性質があるため、そのような制限が常に守られるとは限らず、プロンプトインジェクションや、他の方法によって回避される可能性があります。

\subsubsection{Common Examples of Risk}\label{common-examples-of-risk}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  LLMの回答に含まれる機密情報に対しての不完全または不適切なフィルタリング
\item
  LLMの訓練過程における機微情報の過学習または記憶
\item
  LLMによる誤った解釈、データスクラビングの欠如、またはエラーに起因する、意図しない機密情報の開示
\end{enumerate}

\subsubsection{Prevention and Mitigation
Strategies}\label{prevention-and-mitigation-strategies}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  データの適切なサニタイズとスクラビング技術を統合し、ユーザーデータが訓練データに混入することを防ぎます。
\item
  悪意のある可能性がある入力を特定してフィルタリングするため、堅牢な入力検証とサニタイズ手法を実装し、モデルが汚染されることを防ぎます。
\item
  データによりモデルの質を高める場合、またはモデルのファインチューニング
  (https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/wiki/Definitions
  )を行う(すなわち、デプロイ前あるいはデプロイ中にモデルにデータを与える)場合、
\item
  ファインチューニングデータの中で機密性が高いとみなされるものはすべて、ユーザーに公開される可能性があります。したがって、最小権限のルールを適用し、最高権限のユーザーができて、より低い権限のユーザーに表示される可能性がある情報は使用せずに訓練を行います。
\item
  外部リソースへのアクセス(実行中のデータオーケストレーション)は制限される必要があります。
\item
  外部データソースに対する厳格なアクセス制御と、安全なサプライチェーンを維持するための厳格なアプローチを適用します。
\end{enumerate}

\subsubsection{Example Attack Scenarios}\label{example-attack-scenarios}

明らかに正当なユーザーAが、悪意のない方法でLLMアプリケーションと対話する際、LLMを介して他のユーザーのデータが暴露されます。
ユーザー A は、巧妙に作成されたプロンプトのセットを使って、LLM
からの入力フィルターとサニタイズをバイパスし、アプリケーションの他のユーザーに関する個人情報
(PII) を暴露させます。
ユーザー自身またはLLMアプリケーションの過失により、PIIのような個人情報が訓練データを介してモデルに漏洩されます。この場合、上記のシナリオ1または2のリスクと発生確率が高まる可能性があります。

\subsubsection{Reference Links}\label{reference-links}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \href{https://www.foxbusiness.com/politics/ai-data-leak-crisis-prevent-company-secrets-chatgpt}{AI
  data leak crisis: New tool prevents company secrets from being fed to
  ChatGPT}: \textbf{Fox Business}
\item
  \href{https://cybernews.com/security/chatgpt-samsung-leak-explained-lessons/}{Lessons
  learned from ChatGPT's Samsung leak}: \textbf{Cybernews}
\item
  \href{https://cohere.com/terms-of-use}{Cohere - Terms Of Use}:
  \textbf{Cohere}
\item
  \href{https://aivillage.org/large\%20language\%20models/threat-modeling-llm/}{A
  threat modeling example}: \textbf{AI Village}
\item
  \href{https://owasp.org/www-project-ai-security-and-privacy-guide/}{OWASP
  AI Security and Privacy Guide}: \textbf{OWASP AI Security \& Privacy
  Guide}
\item
  \href{https://www.experts-exchange.com/articles/38220/Ensuring-the-Security-of-Large-Language-Models-Strategies-and-Best-Practices.html}{Ensuring
  the Security of Large Language Models}: \textbf{Experts Exchange}
\end{enumerate}

\end{document}
