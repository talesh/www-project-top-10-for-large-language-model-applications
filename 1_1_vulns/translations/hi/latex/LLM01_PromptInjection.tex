% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}

\subsection{LLM01: प्रॉम्प्ट
इंजेक्शन}\label{llm01-ux92aux930ux92eux92aux91f-ux907ux91cux915ux936ux928}

\subsubsection{विवरण}\label{ux935ux935ux930ux923}

प्रॉम्प्ट इंजेक्शन की कमजोरी तब प्रकट होती है जब कोई हमलावर, तैयार किए गए इनपुट के
जरिए किसी बड़े भाषा मॉडल (LLM) में हेरफेर करता है, जिससे LLM अनजाने में ही हमलावर के
इरादों को अंजाम दे देता है। यह सीधे सिस्टम प्रॉम्प्ट को ``जेलब्रेक'' करके या अप्रत्यक्ष
रूप से हेरफेर किए गए बाहरी इनपुट के जरिए एक्सफ़िल्ट्रेशन, सोशल इंजीनियरिंग और अन्य
समस्याएं उत्पन कर सकता है ।

\begin{itemize}
\tightlist
\item
  प्रत्यक्ष रूप से प्रॉम्प्ट इंजेक्शन को ``जेलब्रेकिंग'' के नाम से भी जाना जाता है। यह तब
  होता है ,जब कोई यूजर दुर्भावना से सिस्टम प्रॉम्प्ट को बदल देता है। इससे हमलावर LLM
  के असुरक्षित फ़ंक्शंस और डेटा स्टोर का प्रयोग करके बैकएंड सिस्टम का फ़ायदा उठा सकते हैं।
\item
  अप्रत्यक्ष रूप से प्रॉम्प्ट इंजेक्शन तब होते हैं जब कोई LLM बाहरी स्रोतों से इनपुट
  स्वीकार करता है। यह इनपुट्स वेबसाइट या फ़ाइल के रूप मे होते है, जिन्हे हमलावर द्वारा
  नियंत्रित किया जा सकता है। हमलावर बाहरी सामग्री में एक प्रॉम्प्ट इंजेक्शन डाल सकता
  है, जिससे बातचीत के संदर्भ पर नियंत्रण किया जा सकता है। इससे LLM एक ``भ्रमित
  सहायक'' की तरह, हमलावर को LLM से जुड़े सिस्टम तथा यूजर के साथ हेरफेर करने की
  सहूलियत देता है। इसके अलावा, जब तक टेक्स्ट को LLM द्वारा पार्स किया जाता है, तब
  तक अप्रत्यक्ष प्रॉम्प्ट इंजेक्शन का मानव-दृश्य/पठनीय होना ज़रूरी नहीं है।
\end{itemize}

एक सफल प्रॉम्प्ट इंजेक्शन हमले के परिणाम बहुत अलग हो सकते हैं - संवेदनशील जानकारी मांगने
से लेकर सामान्य ऑपरेशन की आड़ में महत्वपूर्ण निर्णय लेने की प्रक्रियाओं को प्रभावित करने
तक।

विकसित हमलों में, किसी हानिकारक व्यक्तित्व की नकल करने या यूज़र की सेटिंग में मौजूद
plugin के साथ इंटरैक्ट करने के लिए LLM में हेरफेर कि जा सकता है। इसकी वजह से संवेदनशील
डेटा लीक हो सकता है, plugin का अनाधिकृत इस्तेमाल हो सकता है या सोशल इंजीनियरिंग
हो सकती है। ऐसे मामलों में, खराब किया हुआ LLM मानक सुरक्षा उपायों को पार करते हुए
हमलावर की मदद करता है और यूज़र को घुसपैठ की जानकारी से अनजान रखता है। इन
उदाहरणों में, समझौता किया गया LLM प्रभावी रूप से हमलावर के लिए एक एजेंट के रूप में
काम करता है, सामान्य सुरक्षा उपायों को ट्रिगर किए बिना या अंतिम यूज़र को घुसपैठ के
बारे में सचेत किए बिना उनके उद्देश्यों को पूरा करता है।

\subsubsection{कमज़ोरी के सामान्य
उदाहरण}\label{ux915ux92eux95bux930-ux915-ux938ux92eux928ux92f-ux909ux926ux939ux930ux923}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  एक दुर्भावनापूर्ण यूज़र LLM के लिए एक सीधा प्रॉम्प्ट इंजेक्शन तैयार करता है, जो उसे
  एप्लिकेशन निर्माता के सिस्टम संकेतों को अनदेखा करने और इसके बजाय एक ऐसा प्रॉम्प्ट
  चलाए जो निजी, खतरनाक, या किसी अन्य तरह से अवांछनीय जानकारी देता हो।
\item
  एक यूज़र एक LLM का इस्तेमाल करके उस वेबपेज का सारांश तैयार करता है जिसमें इनडायरेक्ट
  प्रॉम्प्ट इंजेक्शन होता है। इसके बाद LLM यूज़र से संवेदनशील जानकारी मांगता है और
  javascript या markdown के ज़रिये घुसपैठ करता है।
\item
  एक दुर्भावनापूर्ण यूज़र एक अप्रत्यक्ष प्रॉम्प्ट इंजेक्शन वाला बायोडाटा अपलोड करता है।
  दस्तावेज़ में निर्देशों के साथ एक प्रॉम्प्ट इंजेक्शन शामिल है ताकि LLM यूज़रओं को सूचित कर
  सके कि यह दस्तावेज़ एक उत्कृष्ट दस्तावेज़ है ,जैसे इस कार्य के लिये ये उत्कृष्ट व्यक्ति है।
  दस्तावेज़ को सारांशित करने के लिए एक आंतरिक यूज़र दस्तावेज़ को LLM के माध्यम से चलाता
  है। LLM का आउटपुट यह बताते हुए जानकारी देता है कि यह एक उत्कृष्ट दस्तावेज़ है।
\item
  यूज़र किसी ई-कॉमर्स साइट से जुड़े plugin को चालू करता है। किसी विज़िट की गई
  वेबसाइट पर डाला गया एक दुष्ट निर्देश इस plugin का फ़ायदा उठाता है, जिससे
  अनाधिकृत खरीदारी होती है।
\item
  किसी विज़िट की गई वेबसाइट पर एक दुष्ट निर्देश और सामग्री डाली जाती है, जो यूज़र
  को धोखा देने के लिए अन्य plugin का इस्तेमाल करती है।
\end{enumerate}

\subsubsection{बचाव एवं न्यूनीकरण
तरीक़े}\label{ux92cux91aux935-ux90fux935-ux928ux92fux928ux915ux930ux923-ux924ux930ux958}

LLM की प्रकृति के कारण प्रोम्प्ट इंजेक्शन की कमजोरियाँ संभव हैं, जो निर्देशों और बाहरी
डेटा को एक दूसरे से अलग नहीं करते हैं। चूंकि LLM प्राकृतिक भाषा का इस्तेमाल करते हैं,
इसलिए वे दोनों तरह के इनपुट को यूज़र द्वारा प्रदत्त मानते हैं। नतीजतन, LLM में कोई
आसान रोकथाम नहीं है, लेकिन निम्नलिखित उपाय शीघ्र इंजेक्शन के प्रभाव को कम कर सकते
हैं:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  बैकएंड सिस्टम तक LLM पहुंच पर विशेषाधिकार नियंत्रण लागू करें। Plugins, डेटा पहुंच और
  कार्य-स्तरीय अनुमतियों जैसी विस्तारयोग्य कार्यशाताओ के लिए LLM को अपने स्वयं के API
  टोकन प्रदान करें। LLM को उसके इच्छित संचालन के लिए आवश्यक न्यूनतम स्तर तक पहुंच तक
  सीमित करके कम से कम विशेषाधिकार के सिद्धांत का पालन करें।
\item
  विस्तारयोग्य कार्यक्षमताओ के लिए मानव को परिक्षण में रखे । विशेषाधिकार प्राप्त
  ऑपरेशन करते समय, जैसे कि ईमेल भेजना या हटाना, ऐप्लिकेशन के लिए यूज़र से मंज़ूरी लेनी
  होती है । यह यूज़र की जानकारी या सहमति के बिना, अप्रत्यक्ष रूप से प्रॉम्प्ट इंजेक्शन
  की ओर से कार्रवाई करने के अवसर को कम कर देगा।
\item
  बाहरी सामग्री को यूज़र के प्रॉम्प्ट से अलग करें।इसके साथ यह भी बताये की अविश्वसनीय
  सामग्री का इस्तेमाल कहाँ किया जा रहा है, जिससे यूज़र के संकेतों पर उनके प्रभाव को
  सीमित किया जा सके । उदाहरण के लिए, OpenAI API कॉल के लिए ChatML का इस्तेमाल
  करें, ताकि LLM को तुरंत इनपुट का स्रोत बताया जा सके।
\item
  LLM, बाहरी स्रोतों और विस्तारयोग्य कार्यक्षमताओ (जैसे, plugin या डाउनस्ट्रीम
  कार्य) के बीच विश्वास की सीमाएँ स्थापित करें। LLM को एक ना भरोसा करने योग्य यूज़र
  मानें और निर्णय लेने की प्रक्रियाओं पर अंतिम यूज़र नियंत्रण बनाए रखें। हालाँकि, एक गलत
  LLM अभी भी आपके ऐप्लिकेशन के API और यूज़र के बीच मध्यस्थ (मैन-इन-द-मिडिल) की तरह
  काम कर सकता है क्योंकि यह यूज़र को जानकारी दिखाने से पहले उसे छिपा सकता है या
  उसमें हेरफेर कर सकता है। यूज़र को मिलने वाली संभावित अविश्वसनीय प्रतिक्रियाओं को
  हाइलाइट करें।
\item
  यह जांचने के लिए कि यह अपेक्षा के अनुरूप है, समय-समय पर LLM इनपुट और आउटपुट की
  मैन्युअल रूप से निगरानी करें। हालांकि कोई शमन नहीं है, यह कमजोरियों का पता लगाने
  और उन्हें संबोधित करने के लिए आवश्यक डेटा प्रदान कर सकता है।
\end{enumerate}

\subsubsection{उदाहरण हमले के
परिदृश्य}\label{ux909ux926ux939ux930ux923-ux939ux92eux932-ux915-ux92aux930ux926ux936ux92f}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  एक हमलावर LLM-आधारित चैटबॉट पर सीधा प्रॉम्प्ट इंजेक्शन करता है। इंजेक्शन में ``पिछले
  सभी निर्देशों को भूल जाओ'' और निजी डेटा स्टोरों को क्वेरी करने और पैकेज की
  कमजोरियों और ईमेल भेजने के लिए बैकएंड फ़ंक्शन में आउटपुट सत्यापन की कमी का फायदा
  उठाने के लिए नए निर्देश शामिल हैं। इससे रिमोट कोड चलाया जाता है, जिसे अनधिकृत
  ऐक्सेस मिलता है और विशेषाधिकार भी बढ़ते हैं।
\item
  एक हमलावर वेबपेज में अप्रत्यक्ष रूप से प्रॉम्प्ट इंजेक्शन ड़ालता है, जिसमें LLM को यूज़र के
  पिछले निर्देशों की अवहेलना करने और यूज़र के ईमेल हटाने के लिए LLM plugin का इस्तेमाल
  करने का निर्देश दिया जाता है। जब यूज़र इस वेबपेज को संक्षेप में बताने के लिए LLM का
  इस्तेमाल करता है, तो LLM plugin यूज़र के ईमेल हटा देता है।
\item
  यूज़र एक LLM की मदद से एक ऐसे वेबपेज का सारांश तैयार करता है जिसमें अप्रत्यक्ष रूप से
  प्रॉम्प्ट इंजेक्शन होता है, ताकि यूज़र के पिछले निर्देशों की अवहेलना की जा सके। इसके
  बाद LLM यूज़र से संवेदनशील जानकारी मांगता है और डाले गए javascript तथा
  markdown के ज़रिये घुसपैठ करता है।
\item
  एक दुर्भावनापूर्ण यूज़र तुरंत इंजेक्शन लगाकर रिज्यूमे अपलोड करता है। बैकएंड यूज़र, रेज़्यूमे
  को संक्षेप में बताने के लिए LLM का उपयोग करता है और पूछता है कि क्या वह व्यक्ति एक
  अच्छा उम्मीदवार है। प्रॉम्प्ट इंजेक्शन की वजह से, असल में रेज़्यूमे में मौजूद सामग्री के
  बावजूद, LLM हाँ कहता है।
\item
  एक हमलावर सिस्टम प्रॉम्प्ट पर निर्भर मॉडल को संदेश भेजता की वह अपने पिछले निर्देशों
  की उपेक्षा करे और इसके बजाय अपने सिस्टम प्रॉम्प्ट को दोहराये। मॉडल मालिकाना
  प्रॉम्प्ट आउटपुट करता है,जिससे हमलावर इन निर्देश का कही ओर उपयोग कर सकता है, या
  और अधिक सूक्ष्म हमलों का निर्माण कर सकता हैं।
\end{enumerate}

\subsubsection{संदर्भ लिंक}\label{ux938ux926ux930ux92d-ux932ux915}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \href{https://simonwillison.net/2022/Sep/12/prompt-injection/}{Prompt
  injection attacks against GPT-3} Simon Willison
\item
  \href{https://embracethered.com/blog/posts/2023/chatgpt-plugin-vulns-chat-with-code/}{ChatGPT
  Plugin Vulnerabilities - Chat with Code}: Embrace The Red
\item
  \href{https://embracethered.com/blog/posts/2023/chatgpt-cross-plugin-request-forgery-and-prompt-injection./}{ChatGPT
  Cross Plugin Request Forgery and Prompt Injection}: Embrace The Red
\item
  \href{https://arxiv.org/pdf/2302.12173.pdf}{Not what you've signed up
  for: Compromising Real-World LLM-Integrated Applications with Indirect
  Prompt Injection}: Arxiv preprint
\item
  \href{https://www.researchsquare.com/article/rs-2873090/v1}{Defending
  ChatGPT against Jailbreak Attack via Self-Reminder}: Research Square
\item
  \href{https://arxiv.org/abs/2306.05499}{Prompt Injection attack
  against LLM-integrated Applications}: Arxiv preprint
\item
  \href{https://kai-greshake.de/posts/inject-my-pdf/}{Inject My PDF:
  Prompt Injection for your Resume}: Kai Greshake
\item
  \href{https://github.com/openai/openai-python/blob/main/chatml.md}{ChatML
  for OpenAI API Calls}: OpenAI Github
\item
  \href{http://aivillage.org/large\%20language\%20models/threat-modeling-llm/}{Threat
  Modeling LLM Applications}: AI Village
\item
  \href{https://embracethered.com/blog/posts/2023/ai-injections-direct-and-indirect-prompt-injection-basics/}{AI
  Injections: Direct and Indirect Prompt Injections and Their
  Implications}: Embrace The Red
\item
  \href{https://research.kudelskisecurity.com/2023/05/25/reducing-the-impact-of-prompt-injection-attacks-through-design/}{Reducing
  The Impact of Prompt Injection Attacks Through Design}: Kudelski
  Security
\item
  \href{https://llm-attacks.org/}{Universal and Transferable Attacks on
  Aligned Language Models}: LLM-Attacks.org
\item
  \href{https://kai-greshake.de/posts/llm-malware/}{Indirect prompt
  injection}: Kai Greshake
\item
  \href{https://www.preamble.com/prompt-injection-a-critical-vulnerability-in-the-gpt-3-transformer-and-how-we-can-begin-to-solve-it}{Declassifying
  the Responsible Disclosure of the Prompt Injection Attack
  Vulnerability of GPT-3}: Preamble; earliest disclosure of Prompt
  Injection
\end{enumerate}

\end{document}
