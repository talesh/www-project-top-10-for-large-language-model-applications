% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}

\subsection{LLM09:
ओवररिलायंस}\label{llm09-ux913ux935ux930ux930ux932ux92fux938}

\subsubsection{विवरण}\label{ux935ux935ux930ux923}

ज़्यादा निर्भरता तब होती है जब सिस्टम या लोग बिना पर्याप्त निरीक्षण के निर्णय लेने
या कॉन्टेंट तैयार करने के लिए LLM पर निर्भर होते हैं। LLM रचनात्मक और जानकारीपूर्ण
सामग्री तैयार कर सकते हैं, लेकिन वे ऐसी सामग्री भी जेनरेट कर सकते हैं जो तथ्यात्मक रूप से
गलत, अनुचित या असुरक्षित हो। इसे भ्रम या उलझन कहा जाता है और इसकी वजह से ग़लत
सूचना, ग़लतफ़हमी, कानूनी समस्याएं और प्रतिष्ठा को नुकसान हो सकता है।

LLM द्वारा बनाया गया सोर्स कोड अज्ञात सुरक्षा कमजोरियों उत्पन्न कर सकता है। यह
एप्लीकेशन की सुरक्षा एवं परिचालन सुरक्षा के लिए एक जोखिम पैदा करता है। ये जोखिम
समीक्षा की कठोर प्रक्रिया के महत्व को दर्शाते हैं, इसके साथ:

\begin{itemize}
\tightlist
\item
  ओवरसाइट (Oversight)
\item
  सत्यापन की निरंतर व्यवस्था (Continuous validation mechanism)
\item
  अस्वीकार्य जो जोखिम में हैं (Disclaimers on risk)
\end{itemize}

\subsubsection{कमज़ोरी के सामान्य
उदाहरण}\label{ux915ux92eux95bux930-ux915-ux938ux92eux928ux92f-ux909ux926ux939ux930ux923}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  LLM प्रतिक्रिया के तौर पर गलत जानकारी देता है, एवं वह इन जानकारियों को अत्यधिक
  आधिकारिक रूप मे प्रदर्शित करता है। प्रणाली को उचित जांच और संतुलन के बिना डिज़ाइन
  किया गया है, जिससे यह दिक्कत संभाल नहीं पाती और परिणामस्वरूप उपयोगकर्ता को
  भ्रामक जानकारी मिलती है ।
\item
  एलएलएम असुरक्षित या दोषपूर्ण कोड सुझाता है, जो उचित निरीक्षण या सत्यापन के बिना
  सॉफ़्टवेयर सिस्टम में शामिल होने पर कमजोरियों को जन्म देता है।
\end{enumerate}

\subsubsection{बचाव कैसे करें}\label{ux92cux91aux935-ux915ux938-ux915ux930}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  LLM आउटपुट की नियमित निगरानी और उनकी समीक्षा करें। इन्कन्सीस्टेन्ट टेक्स्ट
  (inconsistent text) को फ़िल्टर करने के लिए आत्म स्थिरता (self-consistency)
  या वोटिंग तकनीकों का इस्तेमाल करें। एक ही प्रॉम्प्ट के लिए कई मॉडल प्रतिक्रियाओं की
  तुलना करने से आउटपुट की गुणवत्ता और निरंतरता का बेहतर आकलन किया जा सकता है।
\item
  विश्वसनीय बाहरी स्रोतों से LLM आउटपुट को क्रॉस-चेक करें।अतिरिक्त पुष्टि से यह पक्का
  करने में मदद मिल सकती है कि मॉडल के ज़रिये दी गई जानकारी सटीक एवं भरोसेमंद है।
\item
  फ़ाइन-ट्यूनिंग या एम्बेडिंग की मदद से आउटपुट को बेहतर बनाएं। किसी खास क्षेत्र के किए
  बनाये गए मॉडल की तुलना में जेनेरिक पहले से प्रशिक्षित मॉडल से गलत जानकारी मिलने की
  संभावना ज़्यादा होती है। इसके लिए प्रॉम्प्ट इंजीनियरिंग (prompt engineering),
  पैरामीटर एफ़िशिएंट ट्यूनिंग (parameter efficient tuning), फ़ुल मॉडल ट्यूनिंग
  (full model tuning) और चेन ऑफ़ थॉट (chain of thought) प्रॉम्प्टिंग जैसी
  तकनीकों का इस्तेमाल किया जा सकता है।
\item
  ऑटोमैटिक सत्यापन तंत्र लागू करें, जो ज्ञात तथ्यों या डेटा के विरुद्ध जनरेट किए गए
  आउटपुट की क्रॉस-पुष्टि कर सके। यह सुरक्षा की एक अतिरिक्त परत प्रदान कर, मतिभ्रम
  से जुड़े जोखिमों को कम कर सकता है।
\item
  जटिल टास्क को सबटास्क में बांटें और उन्हें अलग-अलग एजेंटों को सौंपें, जो जटिलताओं को
  नियंत्रित करने में मदद करता है,और मतिभ्रम की संभावना को भी कम करता है क्योंकि हर
  एजेंट को एक छोटे से काम के लिए जिम्मेदार ठहराया जा सकता है।
\item
  LLM के इस्तेमाल से जुड़े जोखिमों और सीमाओं के बारे में जानकारी दे, जो प्रभावी जोखिम
  संचार यूज़र को संभावित समस्याओं के लिए तैयार कर सकता कर सही निर्णय लेने में मदद कर
  सकता है।
\item
  ऐसे API और यूज़र इंटरफेस बनाएं, जो LLM के ज़िम्मेदार और सुरक्षित इस्तेमाल को
  प्रोत्साहित करें। इसमें कॉन्टेंट फ़िल्टर, संभावित अशुद्धियों के बारे में यूज़र की चेतावनियां
  और AI द्वारा जेनरेट की गई सामग्री की क्लियर लेबलिंग जैसे उपाय शामिल हैं।
\item
  विकास के दौरान ही LLM को संभावित कमजोरियों से बचाने के लिए सुरक्षित कोडिंग
  तकनीके एवं दिशानिर्देशों को स्थापित करें।
\end{enumerate}

\subsubsection{उदाहरण हमले का
परिदृश्य}\label{ux909ux926ux939ux930ux923-ux939ux92eux932-ux915-ux92aux930ux926ux936ux92f}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  समाचार संगठन समाचार बनाने के लिए AI मॉडल का ज़्यादा इस्तेमाल करता है। एक
  दुर्भावनापूर्ण व्यक्ति इस अति-निर्भरता का फायदा उठाता है, AI को गुमराह करने वाली
  जानकारी देता है, जिससे गलत सूचनाएं फैलती हैं। AI ने अनजाने में ही सामग्री को
  प्लगिराइज़्ड ( plagiarized) कर दिया, जिससे कॉपीराइट समस्याएँ पैदा हो गईं और
  संगठन में विश्वास कम हो गया।
\item
  सॉफ़्टवेयर डेवलपमेंट टीम कोडिंग प्रक्रिया में तेज़ी लाने के लिए कोडेक्स जैसे AI सिस्टम का
  इस्तेमाल करती है। AI के सुझावों पर ज़्यादा भरोसा करने से सुरक्षा डिफ़ॉल्ट सेटिंग या
  सुरक्षित कोडिंग पद्धतियों के साथ असंगत सुझावों के कारण ऐप्लिकेशन में सुरक्षा संबंधी
  कमजोरियाँ आ जाती हैं।
\item
  एक सॉफ़्टवेयर डेवलपमेंट फर्म डेवलपर्स की सहायता के लिए LLM का इस्तेमाल करती है। LLM
  एक गैर-मौजूद कोड लाइब्रेरी या पैकेज का सुझाव देता है, और एक डेवलपर, जो AI पर
  भरोसा करता है, अनजाने में एक दुर्भावनापूर्ण पैकेज को फर्म के सॉफ़्टवेयर में इंटीग्रेट कर
  देता है। यह AI सुझावों को क्रॉस-चेकिंग करने के महत्व पर प्रकाश डालता है, खासकर
  तीसरे पक्ष के कोड या लाइब्रेरी को शामिल करते समय।
\end{enumerate}

\subsubsection{संदर्भ लिंक}\label{ux938ux926ux930ux92d-ux932ux915}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \href{https://towardsdatascience.com/llm-hallucinations-ec831dcd7786}{Understanding
  LLM Hallucinations}: Towards Data Science
\item
  \href{https://www.techpolicy.press/how-should-companies-communicate-the-risks-of-large-language-models-to-users/}{How
  Should Companies Communicate the Risks of Large Language Models to
  Users?}: Techpolicy
\item
  \href{https://www.washingtonpost.com/media/2023/01/17/cnet-ai-articles-journalism-corrections/}{A
  news site used AI to write articles. It was a journalistic disaster}:
  Washington Post
\item
  \href{https://vulcan.io/blog/ai-hallucinations-package-risk}{AI
  Hallucinations: Package Risk}: Vulcan.io
\item
  \href{https://thenewstack.io/how-to-reduce-the-hallucinations-from-large-language-models/}{How
  to Reduce the Hallucinations from Large Language Models}: The New
  Stack
\item
  \href{https://newsletter.victordibia.com/p/practical-steps-to-reduce-hallucination}{Practical
  Steps to Reduce Hallucination}: Victor Debia
\end{enumerate}

\end{document}
