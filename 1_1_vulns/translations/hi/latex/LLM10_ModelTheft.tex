% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}

\subsection{LLM10: मॉडल चोरी}\label{llm10-ux92eux921ux932-ux91aux930}

\subsubsection{विवरण}\label{ux935ux935ux930ux923}

यह दुर्भावनापूर्ण व्यक्तियों या APTs द्वारा LLM मॉडल में अनधिकृत पहुंच और घुसपैठ को
संदर्भित करती है। यह तब होता है जब LLM मॉडल (मूल्यवान बौद्धिक संपदा होने के नाते),के
साथ छेड़छाड़ की जाती है, भौतिक रूप से चोरी हो जाते हैं, कॉपी किए जाते हैं या एक
कार्यात्मक समकक्ष बनाने के लिए वज़न और पैरामीटर निकाले जाते हैं। LLM मॉडल की चोरी के
प्रभाव में आर्थिक और ब्रांड प्रतिष्ठा खोना, प्रतिस्पर्धात्मक लाभ में कमी, मॉडल का
अनधिकृत उपयोग या मॉडल में मौजूद संवेदनशील जानकारी तक अनधिकृत पहुंच शामिल हो सकती
है।

LLM की चोरी सुरक्षा के लिए एक महत्वपूर्ण चिंता का विषय है क्योंकि भाषा मॉडल तेजी से
शक्तिशाली और प्रचलित होते जा रहे हैं। संगठनों और शोधकर्ताओं को अपने LLM मॉडल की
सुरक्षा के लिए मज़बूत सुरक्षा उपायों को प्राथमिकता देनी चाहिए, जिससे उनकी बौद्धिक
संपदा की गोपनीयता और सत्यनिष्ठा बनी रहे। LLM मॉडल चोरी से जुड़े जोखिमों को कम करने
और LLM पर निर्भर व्यक्तियों और संगठनों दोनों के हितों की सुरक्षा करने के लिए एक व्यापक
सुरक्षा ढांचे का इस्तेमाल करना, जिसमें ऐक्सेस नियंत्रण, एन्क्रिप्शन और निरंतर निगरानी
शामिल है तथा महत्वपूर्ण है।

\subsubsection{कमज़ोरी के सामान्य
उदाहरण}\label{ux915ux92eux95bux930-ux915-ux938ux92eux928ux92f-ux909ux926ux939ux930ux923}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  एक हमलावर कंपनी के कमजोर इंफ्रास्ट्रक्चर का फायदा उठा, कंपनी के नेटवर्क या
  ऐप्लिकेशन सुरक्षा सेटिंग में ग़लतफ़हमी के ज़रिए LLM मॉडल रिपॉजिटरी तक अनधिकृत पहुंच
  बनता है।
\item
  अंदरूनी खतरे का परिदृश्य जहां एक असंतुष्ट कर्मचारी किसी मॉडल या उससे जुड़ी सामग्री
  को लीक कर देता है।
\item
  एक हमलावर API से सावधानी से तैयार किए गए इनपुट और प्रॉम्प्ट इंजेक्शन तकनीकों का
  इस्तेमाल करके पूछताछ करता है, जिससे की शैडो मॉडल बनाने के लिए पर्याप्त संख्या में
  आउटपुट प्राप्त होते है।
\item
  एक दुर्भावनापूर्ण हमलावर एक साइड-चैनल हमला करने के लिए LLM की इनपुट फ़िल्टरिंग
  तकनीकों को दरकिनार कर सकता है और अंतत: रिमोट नियंत्रित संसाधन का उपयोग करके
  मॉडल के आर्किटेक्चर और उससे जुडी जानकारियां हासिल कर सकता है।
\item
  मॉडल एक्सट्रैक्शन के अटैक वेक्टर में किसी खास विषय पर बड़ी संख्या में प्रॉम्प्ट्स के साथ
  LLM से पूछताछ करना शामिल है। इसके बाद LLM के आउटपुट का इस्तेमाल किसी दूसरे मॉडल
  को ठीक करने के लिए किया जा सकता है। हालाँकि, इस हमले के बारे में कुछ बातें ध्यान देने
  योग्य हैं:।

  \begin{itemize}
  \tightlist
  \item
    हमलावर को बड़ी संख्या में लक्षित प्रोम्प्ट जेनरेट करने होंगे। अगर प्रोम्प्ट पर्याप्त
    नहीं हैं, तो LLM से मिलने वाले आउटपुट बेकार होंगे।
  \item
    LLM के आउटपुट में कभी-कभी बेहूदा जवाब हो सकते हैं, मतलब हमलावर पूरे मॉडल को
    निकालने में सक्षम नहीं हो सकता क्योंकि कुछ आउटपुट बेतुके हो सकते हैं।

    \begin{itemize}
    \tightlist
    \item
      मॉडल एक्सट्रैक्शन के ज़रिये किसी LLM को 100\% बनाना संभव नहीं है। हालांकि,
      हमलावर एक अपूर्ण (partial) मॉडल बना सकता है।
    \end{itemize}
  \end{itemize}
\item
  फ़ंक्शनल मॉडल रेप्लिकेशन के अटैक वेक्टर में सिंथेटिक प्रशिक्षण डेटा (``सेल्फ़-इंस्ट्रक्ट''
  नामक दृष्टिकोण) जेनरेट करने के लिए प्रॉम्प्ट्स को लक्षित मॉडल पर उपयोग करना, फिर
  उसका इस्तेमाल कर किसी अन्य मूलभूत मॉडल को फ़ाइन-ट्यून करना शामिल है। यह उदाहरण
  5 में इस्तेमाल किए गए पारंपरिक क्वेरी-आधारित (query-based) एक्सट्रैक्शन की सीमाओं
  को दरकिनार कर देता है और शोध कार्य के लिये किसी अन्य LLM को प्रशिक्षित करने के
  लिए सफलतापूर्वक इस्तेमाल करता है। हालांकि इस शोध के संदर्भ में, मॉडल रेप्लिकेशन कोई
  हमला नहीं है। इस दृष्टिकोण का इस्तेमाल एक हमलावर किसी मालिकाना मॉडल को
  सार्वजनिक API की मदद से बनाने के लिए कर सकता है।
\end{enumerate}

किसी चोरी हुए मॉडल का इस्तेमाल, शैडो मॉडल के तौर पर, प्रतिकूल हमलों को स्टेज करने के
लिए किया जा सकता है, जिसमें मॉडल में मौजूद संवेदनशील जानकारी तक अनाधिकृत पहुंच एवं
एडवांस प्रॉम्प्ट इंजेक्शन को आगे बढ़ाने के लिए प्रतिकूल इनपुट के साथ प्रयोग करना शामिल
है, जिसका पता नहीं चलता है।

\subsubsection{बचाव कैसे करें}\label{ux92cux91aux935-ux915ux938-ux915ux930}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  LLM मॉडल रिपॉजिटरी और प्रशिक्षण वातावरण तक अनधिकृत पहुंच को सीमित करने के लिए
  मज़बूत ऐक्सेस नियंत्रण (जैसे, RBAC और कम से कम विशेषाधिकार का नियम) और मज़बूत
  प्रमाणीकरण (authentication) तंत्र लागू करें।

  \begin{itemize}
  \tightlist
  \item
    यह पहले तीन सामान्य उदाहरणों के लिए खास तौर पर सही है, जो अंदरूनी खतरों, गलत
    कॉन्फ़िगरेशन और/या इंफ्रास्ट्रक्चर के बारे में कमज़ोर सुरक्षा नियंत्रण के कारण इस
    जोखिम का कारण बन सकते हैं, जिसमें LLM मॉडल, वज़न और आर्किटेक्चर मौजूद हैं, जिसमें
    एक दुर्भावनापूर्ण व्यक्ति वातावरण के अंदर या बाहर से घुसपैठ कर सकता है।
  \item
    सप्लाई-चेन के हमलों को रोकने के लिए आपूर्तिकर्ता प्रबंधन ट्रैकिंग, सत्यापन और
    निर्भरता की कमजोरियाँ महत्वपूर्ण विषय हैं।
  \end{itemize}
\item
  नेटवर्क संसाधनों, आंतरिक सेवाओं और API तक LLM की पहुँच को प्रतिबंधित करें।

  \begin{itemize}
  \tightlist
  \item
    यह सभी सामान्य उदाहरणों के लिए खास तौर पर सही है क्योंकि यह अंदरूनी जोखिमों
    और खतरों को कवर करता है, अंत में यह नियंत्रित करता है कि LLM एप्लिकेशन की पहुंच
    कहा तक है और इसलिए यह साइड-चैनल हमलों को रोकने के लिए एक तंत्र हो सकता है।
  \end{itemize}
\item
  उत्पादन वाले एमएल मॉडल के लिए एक केंद्रीकृत एमएल मॉडल इन्वेंटरी या रजिस्ट्री का
  उपयोग करें। यह होने से एक्सेस नियंत्रण, प्रमाणीकरण और निगरानी/लॉगिंग के माध्यम से
  LLM मॉडल तक अनधिकृत पहुंच को रोका जा सकता है जो गवर्नन्स (governance) के लिए
  नींव हैं। यह अनुपालन, जोखिम मूल्यांकन और जोखिम शमन के लिए मॉडलों द्वारा प्रयोग की
  गई एल्गोरिदम के बारे में डेटा एकत्र करने के लिए भी फायदेमंद है।
\item
  किसी भी संदिग्ध या अनधिकृत व्यवहार का तुरंत पता लगाने और उसका जवाब देने के लिए,
  LLM मॉडल रिपॉजिटरी से संबंधित एक्सेस लॉग और गतिविधियों की नियमित रूप से
  निगरानी करें और उनका ऑडिट करें।
\item
  इंफ्रास्ट्रक्चर में ऐक्सेस और डिप्लॉयमेंट नियंत्रणों को बेहतर बनाने के लिए, गवर्नेंस, ट्रैकिंग
  और कार्यप्रवाह की मंज़ूरी की मदद से MLOP के डिप्लॉयमेंट को स्वचालित करें।
\item
  साइड-चैनल अटैक की वजह से प्रॉम्प्ट इंजेक्शन तकनीकों के जोखिम को कम करने के लिए
  नियंत्रण और शमन रणनीतियां लागू करें।
\item
  API कॉल फ़िल्टर की दर सीमित कर, LLM ऐप्लिकेशन से डेटा में घुसपैठ के जोखिम को कम
  किया जा सकता है, या अन्य निगरानी प्रणालियों से (जैसे, DLP) निकास की गतिविधि
  का पता लगाने के लिए तकनीकों को लागू किया जा सकता है।
\item
  निष्कर्ष संबंधी प्रश्नों का पता लगाने और भौतिक सुरक्षा उपायों को मजबूत करने में मदद
  करने के लिए प्रतिकूल एवं सुदृढ़ प्रशिक्षण लागू करें।
\item
  LLM के जीवनचक्र में एम्बेडिंग और खोजने के चरणों में वॉटरमार्किंग फ़्रेमवर्क लागू करें।
\end{enumerate}

\subsubsection{उदाहरण हमले का
परिदृश्य}\label{ux909ux926ux939ux930ux923-ux939ux92eux932-ux915-ux92aux930ux926ux936ux92f}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  एक हमलावर किसी कंपनी के LLM मॉडल भंडार तक अनधिकृत पहुंच प्राप्त करने के लिए उसके
  बुनियादी ढांचे में कमजोरियों का फायदा उठाता है। इसके बाद हमलावर मूल्यवान LLM
  मॉडलों में घुसबैठ करता है। जिसका इस्तेमाल वह प्रतिस्पर्धी भाषा प्रोसेसिंग सेवा शुरू करने
  या संवेदनशील जानकारी निकालने के लिए करता है, जिससे कंपनी को काफी आर्थिक नुकसान
  होता है।
\item
  एक असंतुष्ट कर्मचारी मॉडल या उससे संबंधित जानकारिया लीक कर देता है। इन
  जानकारियों के सार्वजनिक प्रदर्शन से हमलावरों के लिए ग्रे बॉक्स प्रतिकूल हमला तथा
  संपत्ति की सीधा चोरी आसान हो गया ।
\item
  एक हमलावर सावधानी से चुने गए इनपुट के साथ API से पूछताछ करता है और शैडो मॉडल
  बनाने के लिए पर्याप्त संख्या में आउटपुट इकट्ठा करता है।
\item
  एक सुरक्षा नियंत्रण विफलता सप्लाई चेन के भीतर मौजूद है जो मालिकाना मॉडल जानकारी
  के डेटा लीक की ओर ले जाती है।
\item
  एक दुर्भावना वाला हमलावर साइड-चैनल हमला करने और अपने नियंत्रण के तहत रिमोट
  नियंत्रित संसाधन पर मॉडल जानकारी पुनर्प्राप्त करने के लिए इनपुट फ़िल्टरिंग तकनीकों
  और LLM की प्रस्तावना को बायपास करता है।
\end{enumerate}

\subsubsection{संदर्भ लिंक}\label{ux938ux926ux930ux92d-ux932ux915}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \href{https://www.theverge.com/2023/3/8/23629362/meta-ai-language-model-llama-leak-online-misuse}{Meta's
  powerful AI language model has leaked online}: The Verge
\item
  \href{https://www.deeplearning.ai/the-batch/how-metas-llama-nlp-model-leaked/}{Runaway
  LLaMA \textbar{} How Meta's LLaMA NLP model leaked}: Deep Learning
  Blog
\item
  \href{https://atlas.mitre.org/tactics/AML.TA0000/}{AML.TA0000 ML Model
  Access}: MITRE ATLAS
\item
  \href{https://arxiv.org/pdf/1803.05847.pdf}{I Know What You See}:
  Arxiv White Paper
\item
  \href{https://www.computer.org/csdl/proceedings-article/sp/2023/933600a432/1He7YbsiH4c}{D-DAE:
  Defense-Penetrating Model Extraction Attacks}: Computer.org
\item
  \href{https://ieeexplore.ieee.org/document/10080996}{A Comprehensive
  Defense Framework Against Model Extraction Attacks}: IEEE
\item
  \href{https://crfm.stanford.edu/2023/03/13/alpaca.html}{Alpaca: A
  Strong, Replicable Instruction-Following Model}: Stanford Center on
  Research for Foundation Models (CRFM)
\item
  \href{https://www.kdnuggets.com/2023/03/watermarking-help-mitigate-potential-risks-llms.html}{How
  Watermarking Can Help Mitigate The Potential Risks Of LLMs?}: KD
  Nuggets
\end{enumerate}

\end{document}
